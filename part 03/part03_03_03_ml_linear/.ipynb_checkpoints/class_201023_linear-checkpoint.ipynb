{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stratify (계층화, 계층추출)\n",
    "랜덤하게 데이터를 뽑을때 각각의 데이터 셋들이 다른 비율의 케이스를 가지는 것을 개선.\n",
    "데이터를 훈련용과 테스트용을 나눠주는데, 각 케이스별 데이터를 동등한 비율로 나눌수 있도록 한다.\n",
    "\n",
    "Ex) 어떤 데이터에, 악성종양 10개, 양성종양 490개의 총 500개의 데이터 있다.\n",
    "* 비-계층적 구조일때. (size=0.5)\n",
    "    - train[악성 5, 양성 240] / test[악성 5, 양성 250]\n",
    "    - train[악성 2, 양성 239] / test[악성 8, 양성 251]\n",
    "\n",
    "* 계층적 구조일때. (size=0.5)\n",
    "    - train[악성 5, 양성 245] / test[악성 5, 양성 245]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형모델 (Linear Model)\n",
    "수업노트 : ch02_01_02_linear_code_v10.html\n",
    "* 특성(feature) 하나이면 -> 직선(line)\n",
    "* 특성 2개이면 -> 면(plane)\n",
    "* 특성 3개이면 -> 초평면(hyperplane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 통해 정해지는 값\n",
    "* 특성이 1 개이면 -> y=w1*x+b\n",
    "* 특성이 2 개이면 -> y=w1*x1 + w2*x2 + b...\n",
    "* 모델이 예측하는 값은 : w1, w2, ... , b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"보스턴 데이터 셋을 활용한 회귀 모델 만들기\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data # input\n",
    "y = boston.target # output\n",
    "\n",
    "print(X.shape, y.shape) # show X and y shapes\n",
    "# (506, 13) (506) row=506, column=13\n",
    "\n",
    "print(boston['feature_names'])\n",
    "# ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'B' 'LSTAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.83885359, 36.00783288, 15.08324755, 25.23090886, 18.87864064])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>실제값</th>\n",
       "      <th>예측값</th>\n",
       "      <th>오차</th>\n",
       "      <th>Absolute Error</th>\n",
       "      <th>Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.838854</td>\n",
       "      <td>-5.238854</td>\n",
       "      <td>5.238854</td>\n",
       "      <td>27.445587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.007833</td>\n",
       "      <td>-3.607833</td>\n",
       "      <td>3.607833</td>\n",
       "      <td>13.016458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.083248</td>\n",
       "      <td>-1.483248</td>\n",
       "      <td>1.483248</td>\n",
       "      <td>2.200023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.230909</td>\n",
       "      <td>-2.430909</td>\n",
       "      <td>2.430909</td>\n",
       "      <td>5.909318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.878641</td>\n",
       "      <td>-2.778641</td>\n",
       "      <td>2.778641</td>\n",
       "      <td>7.720844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>8.8</td>\n",
       "      <td>3.284209</td>\n",
       "      <td>5.515791</td>\n",
       "      <td>5.515791</td>\n",
       "      <td>30.423951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>19.2</td>\n",
       "      <td>23.798796</td>\n",
       "      <td>-4.598796</td>\n",
       "      <td>4.598796</td>\n",
       "      <td>21.148926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>25.3</td>\n",
       "      <td>25.733299</td>\n",
       "      <td>-0.433299</td>\n",
       "      <td>0.433299</td>\n",
       "      <td>0.187748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>20.4</td>\n",
       "      <td>23.048156</td>\n",
       "      <td>-2.648156</td>\n",
       "      <td>2.648156</td>\n",
       "      <td>7.012731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>23.1</td>\n",
       "      <td>24.730468</td>\n",
       "      <td>-1.630468</td>\n",
       "      <td>1.630468</td>\n",
       "      <td>2.658427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      실제값        예측값        오차  Absolute Error  Squared Error\n",
       "0    23.6  28.838854 -5.238854        5.238854      27.445587\n",
       "1    32.4  36.007833 -3.607833        3.607833      13.016458\n",
       "2    13.6  15.083248 -1.483248        1.483248       2.200023\n",
       "3    22.8  25.230909 -2.430909        2.430909       5.909318\n",
       "4    16.1  18.878641 -2.778641        2.778641       7.720844\n",
       "..    ...        ...       ...             ...            ...\n",
       "122   8.8   3.284209  5.515791        5.515791      30.423951\n",
       "123  19.2  23.798796 -4.598796        4.598796      21.148926\n",
       "124  25.3  25.733299 -0.433299        0.433299       0.187748\n",
       "125  20.4  23.048156 -2.648156        2.648156       7.012731\n",
       "126  23.1  24.730468 -1.630468        1.630468       2.658427\n",
       "\n",
       "[127 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dat = {\"실제값\":y_test,\n",
    "           \"예측값\":pred,\n",
    "           \"오차\":y_test - pred,\n",
    "           \"Absolute Error\": np.abs(y_test - pred),\n",
    "           \"Squared Error\": (y_test - pred)**2,}\n",
    "\n",
    "dat = pd.DataFrame(dict_dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3-3 추가 : MAE, MSE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>실제값</th>\n",
       "      <th>예측값</th>\n",
       "      <th>오차</th>\n",
       "      <th>Absolute Error</th>\n",
       "      <th>Squared Error</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.838854</td>\n",
       "      <td>-5.238854</td>\n",
       "      <td>5.238854</td>\n",
       "      <td>27.445587</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.007833</td>\n",
       "      <td>-3.607833</td>\n",
       "      <td>3.607833</td>\n",
       "      <td>13.016458</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.083248</td>\n",
       "      <td>-1.483248</td>\n",
       "      <td>1.483248</td>\n",
       "      <td>2.200023</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.230909</td>\n",
       "      <td>-2.430909</td>\n",
       "      <td>2.430909</td>\n",
       "      <td>5.909318</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.878641</td>\n",
       "      <td>-2.778641</td>\n",
       "      <td>2.778641</td>\n",
       "      <td>7.720844</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>8.8</td>\n",
       "      <td>3.284209</td>\n",
       "      <td>5.515791</td>\n",
       "      <td>5.515791</td>\n",
       "      <td>30.423951</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>19.2</td>\n",
       "      <td>23.798796</td>\n",
       "      <td>-4.598796</td>\n",
       "      <td>4.598796</td>\n",
       "      <td>21.148926</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>25.3</td>\n",
       "      <td>25.733299</td>\n",
       "      <td>-0.433299</td>\n",
       "      <td>0.433299</td>\n",
       "      <td>0.187748</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>20.4</td>\n",
       "      <td>23.048156</td>\n",
       "      <td>-2.648156</td>\n",
       "      <td>2.648156</td>\n",
       "      <td>7.012731</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>23.1</td>\n",
       "      <td>24.730468</td>\n",
       "      <td>-1.630468</td>\n",
       "      <td>1.630468</td>\n",
       "      <td>2.658427</td>\n",
       "      <td>3.06094</td>\n",
       "      <td>22.098695</td>\n",
       "      <td>4.700925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      실제값        예측값        오차  Absolute Error  Squared Error      MAE  \\\n",
       "0    23.6  28.838854 -5.238854        5.238854      27.445587  3.06094   \n",
       "1    32.4  36.007833 -3.607833        3.607833      13.016458  3.06094   \n",
       "2    13.6  15.083248 -1.483248        1.483248       2.200023  3.06094   \n",
       "3    22.8  25.230909 -2.430909        2.430909       5.909318  3.06094   \n",
       "4    16.1  18.878641 -2.778641        2.778641       7.720844  3.06094   \n",
       "..    ...        ...       ...             ...            ...      ...   \n",
       "122   8.8   3.284209  5.515791        5.515791      30.423951  3.06094   \n",
       "123  19.2  23.798796 -4.598796        4.598796      21.148926  3.06094   \n",
       "124  25.3  25.733299 -0.433299        0.433299       0.187748  3.06094   \n",
       "125  20.4  23.048156 -2.648156        2.648156       7.012731  3.06094   \n",
       "126  23.1  24.730468 -1.630468        1.630468       2.658427  3.06094   \n",
       "\n",
       "           MSE      RMSE  \n",
       "0    22.098695  4.700925  \n",
       "1    22.098695  4.700925  \n",
       "2    22.098695  4.700925  \n",
       "3    22.098695  4.700925  \n",
       "4    22.098695  4.700925  \n",
       "..         ...       ...  \n",
       "122  22.098695  4.700925  \n",
       "123  22.098695  4.700925  \n",
       "124  22.098695  4.700925  \n",
       "125  22.098695  4.700925  \n",
       "126  22.098695  4.700925  \n",
       "\n",
       "[127 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_dat = {\"실제값\":y_test,\n",
    "           \"예측값\":pred,\n",
    "           \"오차\":y_test - pred,\n",
    "           \"Absolute Error\": np.abs(y_test - pred),\n",
    "           \"Squared Error\": (y_test - pred)**2,\n",
    "           \"MAE\": np.abs(y_test - pred).sum() / len(pred),\n",
    "           \"MSE\": ((y_test - pred)**2).sum()/len(pred) ,\n",
    "           \"RMSE\":(((y_test - pred)**2).sum()/len(pred))**0.5}\n",
    "\n",
    "dat = pd.DataFrame(dict_dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size :  0.1\n",
      "MAE : 2.834\n",
      "MSE : 14.996\n",
      "RMSE : 3.872\n",
      "\n",
      "test_size :  0.2\n",
      "MAE : 3.189\n",
      "MSE : 24.291\n",
      "RMSE : 4.929\n",
      "\n",
      "test_size :  0.3\n",
      "MAE : 3.163\n",
      "MSE : 21.517\n",
      "RMSE : 4.639\n",
      "\n",
      "test_size :  0.4\n",
      "MAE : 3.298\n",
      "MSE : 21.833\n",
      "RMSE : 4.673\n",
      "\n",
      "test_size :  0.5\n",
      "MAE : 3.398\n",
      "MSE : 25.175\n",
      "RMSE : 5.018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3-4 추가 : 데이터 분리 비율 (9:1, 8:2, 7:3)\n",
    "\n",
    "for i in range(1, 6, 1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(i/10), random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred[:5]\n",
    "    \n",
    "    mae = np.abs(y_test - pred).sum() / len(pred)\n",
    "    mse = ((y_test - pred)**2).sum()/len(pred)\n",
    "    rmse = (((y_test - pred)**2).sum()/len(pred))**0.5\n",
    "    \n",
    "    print(\"test_size : \",(i/10))\n",
    "    print(\"MAE : {:.3f}\".format(mae))\n",
    "    print(\"MSE : {:.3f}\".format(mse))\n",
    "    print(\"RMSE : {:.3f}\".format(rmse))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀모델에서 score는 결정계수라는 것을 의미한다.\n",
    "* 결정계수는 회귀모델에서 모델의 적합도를 의미하는 것으로 0~1 사이의 값을 갖는다.\n",
    "* 1에 가까울수록 모델이 잘 fitting 되었다. 라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과적합. Over Fitting\n",
    "* 데이터에 대해서는 잘 훈련된 모델이지만 새로운 데이터에의 예측은 꽝.\n",
    "\n",
    "* 대안 2가지\n",
    "    - LASSO 회귀\n",
    "    - Ridge 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import Ridge   # 릿지회귀\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data # input\n",
    "y = boston.target # output\n",
    "\n",
    "print(X.shape, y.shape) # show X and y shapes\n",
    "# (506, 13) (506) row=506, column=13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PolynomialFeatures 메서드\n",
    "- boston dataset의 13개 columns을 가지고 랜덤한 여러개의 변수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글\n",
    "import matplotlib\n",
    "from matplotlib import font_manager, rc\n",
    "font_loc = \"C:/Windows/Fonts/malgunbd.ttf\"\n",
    "font_name = font_manager.FontProperties(fname=font_loc).get_name()\n",
    "matplotlib.rc('font', family=font_name)\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(506,) (506, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 데이터 셋 준비 \n",
    "boston = load_boston()  # 데이터 셋 불러오기\n",
    "print(type(boston.target), type(boston.data))\n",
    "print(boston.target.shape, boston.data.shape)\n",
    "\n",
    "df_boston = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "df_boston['target'] = pd.Series(boston.target)\n",
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target을 예측하는 모델 만들기 (feat. 과적합 개선)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-Normalization dataset :  (506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "# Normalization 하기 전 데이터 보기\n",
    "\n",
    "# Set data X and y\n",
    "X = df_boston.loc[:,'CRIM':'LSTAT']\n",
    "y = boston['target']\n",
    "\n",
    "print(\"pre-Normalization dataset : \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow\n",
    "- 데이터 확장\n",
    "- 모델 선택\n",
    "- 모델 학습\n",
    "- 모델 예측\n",
    "- 예측 결과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "(506, 104) (506,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확장\n",
    "norm_x = MinMaxScaler().fit_transform(X) # 값을 0 ~ 1사이로 만드는 메서드\n",
    "\n",
    "# norm_x\n",
    "print(np.min(norm_x), np.max(norm_x)) # norm_x 최소, 최대를 보면, 0 and 1 사이로 변경되었음을 알 수 있다.\n",
    "\n",
    "# 변수의 확장\n",
    "ex_X = PolynomialFeatures(degree=2, include_bias=False).fit_transform(norm_x)\n",
    "print(ex_X.shape, y.shape) # (506, 104) (506,)\n",
    "\n",
    "# 변수가 13개 였는데 104개가 되었음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 데이터 셋의 점수 : 0.94\n",
      "테스트 데이터 셋의 점수 : 0.78\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ex_X, y, random_state=42)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(\"학습용 데이터 셋의 점수 : {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 데이터 셋의 점수 : {:.2f}\".format(lr.score(X_test, y_test)))\n",
    "\n",
    "# 학습용 데이터 셋의 점수 : 0.94\n",
    "# 테스트 데이터 셋의 점수 : 0.78\n",
    "\n",
    "# train 스코어가 0.94에서 test에서 0.78로 줄었는데 --> 훈련데이터 모델이 과적합되었음을 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과적합 개선하기 !\n",
    "\n",
    "### L2 규제 (using... Ridge Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 데이터 셋의 점수 : 0.87\n",
      "테스트 데이터 셋의 점수 : 0.81\n"
     ]
    }
   ],
   "source": [
    "lr1 = Ridge().fit(X_train, y_train)\n",
    "\n",
    "print(\"학습용 데이터 셋의 점수 : {:.2f}\".format(lr1.score(X_train, y_train)))\n",
    "print(\"테스트 데이터 셋의 점수 : {:.2f}\".format(lr1.score(X_test, y_test)))\n",
    "\n",
    "# 학습용 데이터 셋의 점수 : 0.87\n",
    "# 테스트 데이터 셋의 점수 : 0.81\n",
    "\n",
    "# train 스코어와 test 스코어의 스코어의 gap이 줄었다 --> '조금 더 일반화 되었다'라고 볼 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3 Ridge method 알파 계수 변경하기\n",
    "* alpha: 0.0001, 0.001, 0.01, 0.1, 1, 10, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "알파값 :  0.0001\n",
      "학습용 데이터 셋의 점수 : 0.94\n",
      "테스트 데이터 셋의 점수 : 0.79\n",
      "\n",
      "알파값 :  0.001\n",
      "학습용 데이터 셋의 점수 : 0.94\n",
      "테스트 데이터 셋의 점수 : 0.81\n",
      "\n",
      "알파값 :  0.01\n",
      "학습용 데이터 셋의 점수 : 0.94\n",
      "테스트 데이터 셋의 점수 : 0.81\n",
      "\n",
      "알파값 :  0.1\n",
      "학습용 데이터 셋의 점수 : 0.92\n",
      "테스트 데이터 셋의 점수 : 0.82\n",
      "\n",
      "알파값 :  1\n",
      "학습용 데이터 셋의 점수 : 0.87\n",
      "테스트 데이터 셋의 점수 : 0.81\n",
      "\n",
      "알파값 :  10\n",
      "학습용 데이터 셋의 점수 : 0.77\n",
      "테스트 데이터 셋의 점수 : 0.73\n",
      "\n",
      "알파값 :  100\n",
      "학습용 데이터 셋의 점수 : 0.56\n",
      "테스트 데이터 셋의 점수 : 0.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4-1\n",
    "for i in (0.0001, 0.001, 0.01, 0.1, 1, 10, 100):\n",
    "    lr1 = Ridge(alpha=i).fit(X_train, y_train)\n",
    "    \n",
    "    print(\"알파값 : \", i)\n",
    "    print(\"학습용 데이터 셋의 점수 : {:.2f}\".format(lr1.score(X_train, y_train)))\n",
    "    print(\"테스트 데이터 셋의 점수 : {:.2f}\".format(lr1.score(X_test, y_test)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # alpha 100 부터는.. 과소적합이라 볼 수 있겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4-1++ plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회귀계수의 최대, 최소 :  -1820.7193438802144 1422.7485462663753\n",
      "회귀계수의 최대, 최소 :  -19.671903528732866 26.23617254240992\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-61bc4900cc98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alpha\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"회귀계수의 최대, 최소 : \", np.min(lr.coef_), np.max(lr.coef_))\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.hlines(0, 0, len(lr.coef_))\n",
    "plt.plot(lr.coef_, 's')\n",
    "plt.title('Linear Regression')\n",
    "\n",
    "for i in (0.0001, 0.001, 0.01, 0.1, 1, 10, 100):\n",
    "    lr1 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "\n",
    "    print(\"회귀계수의 최대, 최소 : \", np.min(lr1.coef_), np.max(lr1.coef_))\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.hlines(0, 0, len(lr1.coef_))\n",
    "    \n",
    "    label=[\"alpha\"+i]\n",
    "    label+=label\n",
    "    \n",
    "    plt.plot(lr1.coef_, 's', label=label)\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (0.0001, 0.001, 0.01, 0.1, 1, 10, 100):\n",
    "    lr1 = Ridge(alpha=i).fit(X_train, y_train)\n",
    "    \n",
    "    print(\"알파값 : \", i)\n",
    "    print(\"학습용 데이터 셋의 점수 : {:.2f}\".format(lr1.score(X_train, y_train)))\n",
    "    print(\"테스트 데이터 셋의 점수 : {:.2f}\".format(lr1.score(X_test, y_test)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # alpha 100 부터는.. 과소적합이라 볼 수 있겠다.\n",
    "\n",
    "for i in range(1, 6, 1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(i/10), random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred[:5]\n",
    "    \n",
    "    mae = np.abs(y_test - pred).sum() / len(pred)\n",
    "    mse = ((y_test - pred)**2).sum()/len(pred)\n",
    "    rmse = (((y_test - pred)**2).sum()/len(pred))**0.5\n",
    "    \n",
    "    print(\"test_size : \",(i/10))\n",
    "    print(\"MAE : {:.3f}\".format(mae))\n",
    "    print(\"MSE : {:.3f}\".format(mse))\n",
    "    print(\"RMSE : {:.3f}\".format(rmse))\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
